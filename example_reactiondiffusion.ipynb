{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a782df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "\n",
    "# import source library with classes und functions\n",
    "import src_hjbnn as src"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183cd073",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f45aafef",
   "metadata": {},
   "outputs": [],
   "source": [
    "################# PARAMETERS ###################################################\n",
    "\n",
    "# set random seed for result reproducibility\n",
    "dtype = 'float32'\n",
    "tf.keras.backend.set_floatx(dtype)\n",
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "\n",
    "# problem parameters: the limits of the considered state space, the constants\n",
    "# for loss weighting in array form [c_1, c_2, c_3] where normalization can be\n",
    "# set in the trainer class as well as the number of training samples,\n",
    "# dt for trajectory calculation in Koopman loss\n",
    "limits = np.array([[-2, 2]]*32)\n",
    "loss_weights = np.array([0.1, 0.9, 0.001])\n",
    "n_samples = 5000\n",
    "dt = 0.001\n",
    "\n",
    "\n",
    "# model parameters: activation function, normalization range, initializer,\n",
    "# pretrain on for Bellcurve, network depth and network width\n",
    "model_activation = src.Bellcurve(0.5)\n",
    "model_normalize = 1\n",
    "model_initializer = tf.keras.initializers.Orthogonal()\n",
    "model_pretrain = 1\n",
    "model_depth = 3\n",
    "model_width = len(limits)\n",
    "\n",
    "\n",
    "# maximum policy iteration steps\n",
    "max_iter = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35acbc31",
   "metadata": {},
   "source": [
    "# Programm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8573aaad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feedback set: [[0.06473397 0.12967229 0.13028686 0.13131617 0.1327679  0.13465281\n",
      "  0.13698494 0.1397817  0.14306405 0.14685668 0.15118825 0.15474904\n",
      "  0.15756597 0.15966034 0.1610479  0.16173908 0.16173908 0.1610479\n",
      "  0.15966034 0.15756597 0.15474904 0.15118825 0.14685668 0.14306405\n",
      "  0.1397817  0.13698494 0.13465281 0.1327679  0.13131617 0.13028686\n",
      "  0.12967229 0.06473397]]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32)]              0         \n",
      "_________________________________________________________________\n",
      "normalizer (Normalizer)      (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 32        \n",
      "=================================================================\n",
      "Total params: 3,200\n",
      "Trainable params: 3,200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "POLICY ITERATION 1/3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feedback set: <function Dynamics.set_feedback_linear.<locals>.<lambda> at 0x0000027164177EE0>\n",
      "transporting 5000 samples with assigned feedback control, done in 1.975797414779663 s\n",
      "transporting 5000 samples with assigned feedback control, done in 1.2921648025512695 s\n",
      "STARTING TRAINING \n",
      "method = tf \n",
      "batch size = 625  \n",
      "train steps = 2000\n",
      "shuffle \t= True\n",
      "\n",
      "SAMPLES (pde, trans, bc) = \t[5000, 5000, 1]\n",
      "LOSS (pde, trans, bc) = \t[0.1   0.9   0.001]/\t[6.0345524e+01 9.8497150e-03 7.2333688e-01] (user)/(normalize) = [1.65712374e-03 9.13732017e+01 1.38248171e-03] (actual)\n",
      "\n",
      "\n",
      "step 0, epoch 1   |   loss [pde, trans, bc]:    train = [6.68E+01  1.11E-02  7.23E-01]    val = [5.82E+01  1.03E-02  7.23E-01]  1.41 s\n",
      "step 100, epoch 13   |   loss [pde, trans, bc]:    train = [3.91E+01  8.44E-03  9.91E-01]    val = [4.66E+01  7.70E-03  9.93E-01]  0.37 s\n",
      "step 200, epoch 26   |   loss [pde, trans, bc]:    train = [6.64E+00  2.08E-04  2.07E-02]    val = [7.17E+00  2.97E-04  2.51E-02]  0.37 s\n",
      "step 300, epoch 38   |   loss [pde, trans, bc]:    train = [1.84E+00  6.08E-05  6.37E-02]    val = [2.03E+00  9.55E-05  6.34E-02]  0.37 s\n",
      "step 400, epoch 51   |   loss [pde, trans, bc]:    train = [7.38E-01  4.07E-05  1.20E-02]    val = [1.29E+00  6.01E-05  1.13E-02]  0.37 s\n",
      "step 500, epoch 63   |   loss [pde, trans, bc]:    train = [6.78E-01  3.74E-05  6.39E-04]    val = [8.97E-01  5.73E-05  3.49E-04]  0.36 s\n",
      "step 600, epoch 76   |   loss [pde, trans, bc]:    train = [1.40E+00  1.68E-05  2.47E-04]    val = [8.99E-01  8.29E-05  7.77E-04]  0.37 s\n",
      "\t stopping counter: \t [1]\n",
      "step 700, epoch 88   |   loss [pde, trans, bc]:    train = [6.53E-01  1.47E-05  3.10E-04]    val = [6.40E-01  2.67E-05  1.79E-04]  0.36 s\n",
      "step 800, epoch 101   |   loss [pde, trans, bc]:    train = [4.85E-01  9.40E-06  3.72E-04]    val = [7.48E-01  2.63E-05  2.26E-04]  0.36 s\n",
      "\t stopping counter: \t [1]\n",
      "step 900, epoch 113   |   loss [pde, trans, bc]:    train = [6.76E+00  1.80E-05  2.81E-05]    val = [3.80E+00  2.34E-05  1.63E-05]  0.36 s\n",
      "\t stopping counter: \t [2]\n",
      "step 900, epoch 901   |   loss [pde, trans, bc]:    train = [2.19E+00  1.04E-05  4.44E-07]    val = [6.40E-01  2.67E-05  1.79E-04]  0.03 s\n",
      "training finished: 900 train steps in 4.74 s\n",
      "STARTING TRAINING \n",
      "method = sc \n",
      "batch size = None  \n",
      "train steps = 100000\n",
      "shuffle \t= True\n",
      "\n",
      "SAMPLES (pde, trans, bc) = \t[5000, 5000, 1]\n",
      "LOSS (pde, trans, bc) = \t[0.1   0.9   0.001]/\t[6.0345524e+01 9.8497150e-03 7.2333688e-01] (user)/(normalize) = [1.65712374e-03 9.13732017e+01 1.38248171e-03] (actual)\n",
      "\n",
      "\n",
      "step 900, epoch 1   |   loss [pde, trans, bc]:    train = [3.14E-01  1.56E-05  2.28E-04]    val = [4.64E-01  2.62E-05  2.28E-04]  0.58 s\n",
      "step 1900, epoch 1001   |   loss [pde, trans, bc]:    train = [2.56E-02  3.63E-07  7.70E-09]    val = [8.69E-02  1.26E-06  7.70E-09]  16.49 s\n",
      "step 2900, epoch 2001   |   loss [pde, trans, bc]:    train = [1.84E-02  2.14E-07  1.36E-07]    val = [7.88E-02  9.19E-07  1.36E-07]  16.53 s\n",
      "step 3900, epoch 3001   |   loss [pde, trans, bc]:    train = [1.53E-02  1.54E-07  3.18E-07]    val = [7.72E-02  7.12E-07  3.18E-07]  15.98 s\n",
      "step 4900, epoch 4001   |   loss [pde, trans, bc]:    train = [1.35E-02  1.22E-07  5.56E-08]    val = [8.04E-02  6.63E-07  5.56E-08]  16.06 s\n",
      "step 5900, epoch 5001   |   loss [pde, trans, bc]:    train = [1.22E-02  1.03E-07  6.68E-08]    val = [7.25E-02  5.03E-07  6.68E-08]  16.00 s\n",
      "step 6900, epoch 6001   |   loss [pde, trans, bc]:    train = [1.14E-02  8.87E-08  2.07E-09]    val = [7.47E-02  4.33E-07  2.07E-09]  15.96 s\n",
      "step 7900, epoch 7001   |   loss [pde, trans, bc]:    train = [1.06E-02  7.63E-08  1.35E-08]    val = [8.79E-02  3.96E-07  1.35E-08]  16.14 s\n",
      "step 8900, epoch 8001   |   loss [pde, trans, bc]:    train = [9.79E-03  6.89E-08  4.12E-08]    val = [9.33E-02  4.28E-07  4.12E-08]  16.06 s\n",
      "step 9206, epoch 8307   |   loss [pde, trans, bc]:    train = [9.62E-03  6.66E-08  2.00E-13]    val = [9.74E-02  4.31E-07  2.00E-13]  4.96 s\n",
      "exit message:  CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH  iterations:  8306\n",
      "training finished: 8306 train steps in 134.76 s\n",
      "\n",
      "\n",
      "\n",
      "POLICY ITERATION 2/3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feedback set: <function InfiniteHorizon.feedback_from_value.<locals>.feedback at 0x0000027165B4FB80>\n",
      "transporting 5000 samples with assigned feedback control, done in 7.476818799972534 s\n",
      "transporting 5000 samples with assigned feedback control, done in 7.8271074295043945 s\n",
      "STARTING TRAINING \n",
      "method = tf \n",
      "batch size = 625  \n",
      "train steps = 2000\n",
      "shuffle \t= True\n",
      "\n",
      "SAMPLES (pde, trans, bc) = \t[5000, 5000, 1]\n",
      "LOSS (pde, trans, bc) = \t[0.1   0.9   0.001]/\t[1.53945663e+02 1.18521182e-02 1.00160085e-01] (user)/(normalize) = [6.49579844e-04 7.59357936e+01 9.98401712e-03] (actual)\n",
      "\n",
      "\n",
      "step 0, epoch 1   |   loss [pde, trans, bc]:    train = [1.51E+02  1.42E-02  1.00E-01]    val = [1.59E+02  1.24E-02  1.00E-01]  1.23 s\n",
      "step 100, epoch 13   |   loss [pde, trans, bc]:    train = [9.19E+01  7.01E-03  5.12E-04]    val = [9.03E+01  7.83E-03  4.26E-04]  0.38 s\n",
      "step 200, epoch 26   |   loss [pde, trans, bc]:    train = [9.28E+00  3.78E-04  6.84E-02]    val = [9.79E+00  4.87E-04  6.72E-02]  0.38 s\n",
      "step 300, epoch 38   |   loss [pde, trans, bc]:    train = [5.33E+00  2.64E-04  1.20E-03]    val = [6.68E+00  1.39E-04  9.49E-04]  0.38 s\n",
      "step 400, epoch 51   |   loss [pde, trans, bc]:    train = [1.86E+00  3.56E-05  1.57E-04]    val = [3.10E+00  6.07E-05  9.03E-05]  0.38 s\n",
      "step 500, epoch 63   |   loss [pde, trans, bc]:    train = [1.27E+00  4.56E-05  2.06E-05]    val = [1.82E+00  3.30E-05  1.17E-05]  0.37 s\n",
      "step 600, epoch 76   |   loss [pde, trans, bc]:    train = [7.97E-01  9.60E-06  9.07E-06]    val = [1.23E+00  2.33E-05  3.16E-06]  0.38 s\n",
      "step 700, epoch 88   |   loss [pde, trans, bc]:    train = [7.29E-01  1.11E-05  7.84E-07]    val = [9.43E-01  2.69E-05  2.93E-05]  0.38 s\n",
      "\t stopping counter: \t [1]\n",
      "step 800, epoch 101   |   loss [pde, trans, bc]:    train = [5.82E-01  6.27E-06  4.06E-05]    val = [7.20E-01  1.59E-05  9.49E-05]  0.38 s\n",
      "step 900, epoch 113   |   loss [pde, trans, bc]:    train = [6.11E-01  9.93E-06  2.20E-05]    val = [7.75E-01  1.42E-05  2.48E-04]  0.38 s\n",
      "step 1000, epoch 126   |   loss [pde, trans, bc]:    train = [4.49E-01  3.44E-06  7.45E-07]    val = [6.95E-01  7.62E-06  5.63E-07]  0.39 s\n",
      "step 1100, epoch 138   |   loss [pde, trans, bc]:    train = [4.66E-01  3.64E-06  2.31E-08]    val = [7.49E-01  8.00E-06  9.39E-06]  0.39 s\n",
      "\t stopping counter: \t [1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1200, epoch 151   |   loss [pde, trans, bc]:    train = [2.22E-01  2.13E-06  6.39E-07]    val = [4.88E-01  8.22E-06  1.20E-05]  0.40 s\n",
      "step 1300, epoch 163   |   loss [pde, trans, bc]:    train = [1.90E-01  2.86E-06  3.35E-07]    val = [3.41E-01  5.81E-06  6.54E-06]  0.40 s\n",
      "step 1400, epoch 176   |   loss [pde, trans, bc]:    train = [1.46E-01  2.86E-06  9.47E-06]    val = [3.29E-01  5.33E-06  3.84E-07]  0.40 s\n",
      "step 1500, epoch 188   |   loss [pde, trans, bc]:    train = [1.35E-01  1.73E-06  8.63E-07]    val = [3.14E-01  5.04E-06  7.94E-07]  0.38 s\n",
      "step 1600, epoch 201   |   loss [pde, trans, bc]:    train = [1.33E-01  1.39E-06  1.50E-06]    val = [3.05E-01  4.77E-06  1.69E-06]  0.39 s\n",
      "step 1700, epoch 213   |   loss [pde, trans, bc]:    train = [1.36E-01  1.75E-06  6.63E-07]    val = [2.98E-01  4.54E-06  6.92E-08]  0.38 s\n",
      "step 1800, epoch 226   |   loss [pde, trans, bc]:    train = [1.19E-01  1.26E-06  5.92E-08]    val = [2.95E-01  4.52E-06  5.92E-08]  0.38 s\n",
      "step 1900, epoch 238   |   loss [pde, trans, bc]:    train = [1.18E-01  1.50E-06  6.23E-08]    val = [2.95E-01  4.52E-06  6.23E-08]  0.38 s\n",
      "\t stopping counter: \t [1]\n",
      "step 2000, epoch 2001   |   loss [pde, trans, bc]:    train = [1.01E-01  1.40E-06  6.32E-08]    val = [2.95E-01  4.52E-06  6.32E-08]  0.40 s\n",
      "training finished: 2000 train steps in 8.92 s\n",
      "STARTING TRAINING \n",
      "method = sc \n",
      "batch size = None  \n",
      "train steps = 100000\n",
      "shuffle \t= True\n",
      "\n",
      "SAMPLES (pde, trans, bc) = \t[5000, 5000, 1]\n",
      "LOSS (pde, trans, bc) = \t[0.1   0.9   0.001]/\t[1.53945663e+02 1.18521182e-02 1.00160085e-01] (user)/(normalize) = [6.49579844e-04 7.59357936e+01 9.98401712e-03] (actual)\n",
      "\n",
      "\n",
      "step 2000, epoch 1   |   loss [pde, trans, bc]:    train = [1.15E-01  1.60E-06  6.35E-08]    val = [2.95E-01  4.52E-06  6.35E-08]  0.77 s\n",
      "step 3000, epoch 1001   |   loss [pde, trans, bc]:    train = [2.68E-02  2.59E-07  9.47E-09]    val = [1.00E-01  9.63E-07  9.47E-09]  18.36 s\n",
      "step 4000, epoch 2001   |   loss [pde, trans, bc]:    train = [2.06E-02  1.47E-07  2.89E-08]    val = [8.09E-02  7.36E-07  2.89E-08]  17.74 s\n",
      "step 5000, epoch 3001   |   loss [pde, trans, bc]:    train = [1.70E-02  9.61E-08  1.39E-08]    val = [7.98E-02  5.82E-07  1.39E-08]  17.34 s\n",
      "step 6000, epoch 4001   |   loss [pde, trans, bc]:    train = [1.49E-02  7.26E-08  8.06E-10]    val = [7.19E-02  4.46E-07  8.06E-10]  17.28 s\n",
      "step 7000, epoch 5001   |   loss [pde, trans, bc]:    train = [1.34E-02  5.99E-08  5.71E-10]    val = [6.56E-02  3.65E-07  5.71E-10]  17.52 s\n",
      "step 8000, epoch 6001   |   loss [pde, trans, bc]:    train = [1.22E-02  5.24E-08  5.57E-10]    val = [6.22E-02  3.08E-07  5.57E-10]  16.59 s\n",
      "step 9000, epoch 7001   |   loss [pde, trans, bc]:    train = [1.12E-02  4.62E-08  1.29E-10]    val = [6.59E-02  3.00E-07  1.29E-10]  14.14 s\n",
      "step 9626, epoch 7627   |   loss [pde, trans, bc]:    train = [1.07E-02  4.35E-08  1.16E-09]    val = [6.85E-02  2.98E-07  1.16E-09]  9.50 s\n",
      "exit message:  CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH  iterations:  7626\n",
      "training finished: 7626 train steps in 129.23 s\n",
      "\n",
      "\n",
      "\n",
      "POLICY ITERATION 3/3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feedback set: <function InfiniteHorizon.feedback_from_value.<locals>.feedback at 0x000002716DDE9AF0>\n",
      "transporting 5000 samples with assigned feedback control, done in 7.345444917678833 s\n",
      "transporting 5000 samples with assigned feedback control, done in 7.380023956298828 s\n",
      "STARTING TRAINING \n",
      "method = tf \n",
      "batch size = 625  \n",
      "train steps = 2000\n",
      "shuffle \t= True\n",
      "\n",
      "SAMPLES (pde, trans, bc) = \t[5000, 5000, 1]\n",
      "LOSS (pde, trans, bc) = \t[0.1   0.9   0.001]/\t[2.4692545e+02 1.2485849e-02 1.6149065e+00] (user)/(normalize) = [4.04980539e-04 7.20816036e+01 6.19230878e-04] (actual)\n",
      "\n",
      "\n",
      "step 0, epoch 1   |   loss [pde, trans, bc]:    train = [2.42E+02  1.47E-02  1.61E+00]    val = [2.46E+02  1.30E-02  1.61E+00]  1.35 s\n",
      "step 100, epoch 13   |   loss [pde, trans, bc]:    train = [1.41E+02  8.38E-03  1.82E+00]    val = [1.54E+02  6.75E-03  1.82E+00]  0.38 s\n",
      "step 200, epoch 26   |   loss [pde, trans, bc]:    train = [2.26E+01  2.37E-04  8.80E-02]    val = [2.40E+01  3.07E-04  8.53E-02]  0.39 s\n",
      "step 300, epoch 38   |   loss [pde, trans, bc]:    train = [5.75E+00  5.96E-05  2.65E-04]    val = [6.16E+00  8.10E-05  3.22E-04]  0.38 s\n",
      "step 400, epoch 51   |   loss [pde, trans, bc]:    train = [2.56E+00  3.28E-05  5.08E-04]    val = [3.29E+00  4.83E-05  7.59E-04]  0.38 s\n",
      "step 500, epoch 63   |   loss [pde, trans, bc]:    train = [1.69E+00  3.07E-05  6.45E-04]    val = [2.20E+00  3.50E-05  5.26E-04]  0.38 s\n",
      "step 600, epoch 76   |   loss [pde, trans, bc]:    train = [1.20E+00  1.51E-05  2.68E-04]    val = [1.42E+00  2.26E-05  3.43E-04]  0.38 s\n",
      "step 700, epoch 88   |   loss [pde, trans, bc]:    train = [9.08E-01  1.34E-05  2.73E-04]    val = [1.07E+00  1.76E-05  4.40E-04]  0.38 s\n",
      "step 800, epoch 101   |   loss [pde, trans, bc]:    train = [8.17E-01  1.45E-05  7.10E-06]    val = [7.51E-01  1.43E-05  1.20E-04]  0.38 s\n",
      "step 900, epoch 113   |   loss [pde, trans, bc]:    train = [4.86E-01  1.30E-05  1.21E-06]    val = [7.64E-01  2.65E-05  1.81E-05]  0.38 s\n",
      "\t stopping counter: \t [1]\n",
      "step 1000, epoch 126   |   loss [pde, trans, bc]:    train = [5.00E-01  4.85E-06  3.01E-04]    val = [6.42E-01  9.78E-06  2.25E-04]  0.38 s\n",
      "step 1100, epoch 138   |   loss [pde, trans, bc]:    train = [3.07E-01  9.25E-06  1.28E-04]    val = [5.03E-01  8.88E-06  5.08E-05]  0.37 s\n",
      "step 1200, epoch 151   |   loss [pde, trans, bc]:    train = [2.13E-01  4.55E-06  1.08E-04]    val = [4.14E-01  7.29E-06  4.91E-05]  0.38 s\n",
      "step 1300, epoch 163   |   loss [pde, trans, bc]:    train = [2.53E-01  3.13E-06  5.66E-05]    val = [3.54E-01  6.48E-06  5.45E-05]  0.37 s\n",
      "step 1400, epoch 176   |   loss [pde, trans, bc]:    train = [2.16E-01  2.33E-06  1.08E-05]    val = [3.26E-01  6.15E-06  3.31E-06]  0.38 s\n",
      "step 1500, epoch 188   |   loss [pde, trans, bc]:    train = [1.95E-01  2.71E-06  1.03E-05]    val = [3.21E-01  5.89E-06  8.59E-06]  0.37 s\n",
      "step 1600, epoch 201   |   loss [pde, trans, bc]:    train = [1.71E-01  2.05E-06  3.89E-05]    val = [3.01E-01  5.70E-06  3.15E-05]  0.38 s\n",
      "step 1700, epoch 213   |   loss [pde, trans, bc]:    train = [2.03E-01  2.00E-06  1.89E-05]    val = [2.99E-01  5.54E-06  1.56E-05]  0.37 s\n",
      "step 1800, epoch 226   |   loss [pde, trans, bc]:    train = [1.65E-01  2.16E-06  1.55E-05]    val = [2.95E-01  5.45E-06  1.55E-05]  0.38 s\n",
      "step 1900, epoch 238   |   loss [pde, trans, bc]:    train = [1.75E-01  2.29E-06  1.54E-05]    val = [2.95E-01  5.45E-06  1.54E-05]  0.39 s\n",
      "step 2000, epoch 2001   |   loss [pde, trans, bc]:    train = [1.40E-01  1.99E-06  1.54E-05]    val = [2.95E-01  5.45E-06  1.54E-05]  0.39 s\n",
      "training finished: 2000 train steps in 8.95 s\n",
      "STARTING TRAINING \n",
      "method = sc \n",
      "batch size = None  \n",
      "train steps = 100000\n",
      "shuffle \t= True\n",
      "\n",
      "SAMPLES (pde, trans, bc) = \t[5000, 5000, 1]\n",
      "LOSS (pde, trans, bc) = \t[0.1   0.9   0.001]/\t[2.4692545e+02 1.2485849e-02 1.6149065e+00] (user)/(normalize) = [4.04980539e-04 7.20816036e+01 6.19230878e-04] (actual)\n",
      "\n",
      "\n",
      "step 2000, epoch 1   |   loss [pde, trans, bc]:    train = [1.58E-01  2.11E-06  1.55E-05]    val = [2.95E-01  5.45E-06  1.55E-05]  0.74 s\n",
      "step 3000, epoch 1001   |   loss [pde, trans, bc]:    train = [2.61E-02  1.46E-07  6.42E-08]    val = [6.15E-02  6.42E-07  6.42E-08]  14.19 s\n",
      "step 4000, epoch 2001   |   loss [pde, trans, bc]:    train = [1.80E-02  9.15E-08  2.24E-07]    val = [7.15E-02  5.68E-07  2.24E-07]  14.54 s\n",
      "step 5000, epoch 3001   |   loss [pde, trans, bc]:    train = [1.52E-02  7.09E-08  2.90E-07]    val = [7.15E-02  4.64E-07  2.90E-07]  14.58 s\n",
      "step 5872, epoch 3873   |   loss [pde, trans, bc]:    train = [1.36E-02  5.98E-08  9.43E-09]    val = [7.72E-02  3.90E-07  9.43E-09]  12.59 s\n",
      "exit message:  CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH  iterations:  3872\n",
      "training finished: 3872 train steps in 56.65 s\n"
     ]
    }
   ],
   "source": [
    "# combine hyperparameters to initializer list\n",
    "initializer = [model_width, model_depth, model_normalize, model_initializer,\n",
    "               limits, model_activation, dtype]\n",
    "\n",
    "\n",
    "# get environment (dynamics) and create control case\n",
    "env, case = src.setup_from_files(A = 'mat_A.npy',\n",
    "                                 B = 'mat_B.npy',\n",
    "                                 Q = 'mat_Q.npy',\n",
    "                                 R = 'mat_R.npy',\n",
    "                                 rhs = lambda x: tf.pow(x, 3.),\n",
    "                                 rhs_np = lambda x: np.pow(x, 3.),\n",
    "                                 dtype = dtype)\n",
    "\n",
    "\n",
    "# set Riccati feedback, this will be used as initial coniditon for the discrete\n",
    "# policy iteration algorithm\n",
    "env.set_feedback_linear(case.K)\n",
    "controller = env.feedback\n",
    "\n",
    "\n",
    "# create monte carlo training and test samples\n",
    "X_train = src.random_states(limits, n_samples)\n",
    "X_test = src.random_states(limits, n_samples)\n",
    "\n",
    "\n",
    "# create neural network model class\n",
    "model_class = src.MLP\n",
    "model = model_class(*initializer)\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# policy iteration\n",
    "for i in range(max_iter):\n",
    "\n",
    "    print('\\n\\n\\nPOLICY ITERATION {}/{}\\n\\n\\n\\n'.format(i+1, max_iter))\n",
    "    controller, v = src.pi_step(case, controller, model_class, initializer,\n",
    "                                loss_weights, model_pretrain, X_train, X_test,\n",
    "                                trans_dt=dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7aa1578",
   "metadata": {},
   "source": [
    "# ANALYSIS ON Sp AND Sp*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13863dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feedback set: <function InfiniteHorizon.feedback_from_value.<locals>.feedback at 0x0000027165918D30>\n",
      "transporting 2000 samples with assigned feedback control, done in 34.564430236816406 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Artem\\AppData\\Local\\Temp/ipykernel_10288/1006537996.py:28: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  axes[0].set_yticklabels([str(int(x)) + '%' for x in axes[0].get_yticks()])\n",
      "C:\\Users\\Artem\\AppData\\Local\\Temp/ipykernel_10288/1006537996.py:36: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  axes[1].set_yticklabels([str(int(x)) + '%' for x in axes[1].get_yticks()])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAADoCAYAAADmFzM8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAftklEQVR4nO3de7gcVZ3u8e9rEgiRWzIIknBJBiJDCALHjUcEPSAIqIh4RoGAmIhODqMG5IAYEAUvKPIwjCBHPRECKCaA4OGiKDJ4uDmIEAmXEBE0gUQwARIkxEAS8ps/1trQNLv33tm7e3fVrvfzPP10d1V11arq7vrVutRaigjMzKx63tDuBJiZWXs4AJiZVZQDgJlZRTkAmJlVlAOAmVlFOQCYmVWUA0AbSVoo6YD8+jRJF9XM+7CkRZJekLSHpJ0k3SdphaTj25dqMxsshrY7AYOFpFuByyPiop6W7UpEfKNu0rnAZyPiurz+i4FbI2KPfiW0hSSNBRYAwyJibZuTY2Y9cA6guLYH5nXz/jUkDWl5isxsUKlsAJC0raSfSnpa0rOSLszT3yDpdEmPS1oq6YeSNsvzhku6PC//nKR7JG0l6SzgXcCFucjmwgbbPCav91lJX6ybd2Ze94aSXgCGAPdL+pOkXwP71az/LZIulfQ9STdKWgnsJ2m0pGvyPi2oLSrK678q788KSfMkdfR0PPK8YyXNl7Rc0k2Stm9wWG/Pz8/ldO7V3fE0s/aqZADIV8s/Ax4HxgJjgCvy7Cn5sR/wj8DGQOfJcDKwGbAt8A/AccCqiPgicAepyGbjiPhsF9ucAHwPOAYYnT+/Tf1yEfFSRGyc3+4WETtExHvq1v/HPP8o4CxgE+A/gRuA+/P+7A98TtJBNas/NO/n5sD1nfvV3fGQdBhwGvA/gTfldMx+3UFN3p2fN8/pvIvuj6eZtVElAwDwdtJJ+PMRsTIiXoyIO/O8o4HzIuLPEfECcCpwpKShwBrSiXvHiHg5IuZExPO93OZHgJ9FxO0R8RLwJWBdP/fjuoj4TUSsA3YF3hQRX42I1RHxZ+AHwJE1y98ZETdGxMvAj4Dd8vTujsf/Ar4ZEfNzuf43gN27yQXU6+54mlkbVTUAbAs83qCicjTpSrjT46TK8q1IJ82bgCskPSnpHEnDernN0cCizjcRsRJ4ti+Jr7Go5vX2wOhcNPWcpOdIV+5b1Szz15rXfweG5xNxd8dje+D8mnUuA0TKJfRGd8fTzNqoqldhi4DtJA3t4qT3JOmk12k7YC2wJC/7FeArucXLjcAjwMVAT92qPgXs3PlG0ghSbqI/are5CFgQEeP7sJ7ujsci4KyI+PF6pqdTw+PZh3SaWRNVNQfwO9IJ+WxJb8yVu3vnebOBEyWNk7QxqcjjyohYK2k/SbvmMvPnSUVCL+fPLSGVcTdyNXCIpH0kbQB8leYe/98Bz0v6gqSNJA2RNFHSnr38bKPj8X3gVEm7AEjaTNJHG6znaVKxVu1xaHg8+7CPZtZElQwAuQz8g8COwBPAYuCIPHsmqajndlKb9heBaXnem0kn8ueB+cBtwOV53vnAR3JLmQu62OY84DPALNLJdnnebrP3afec7meAi0iV1r397OuOR0T8P+BbpGKv54GHgPc1WM/fSZXSv8lFRu+g++NpZm0kDwhjZlZNlcwBmJmZA4CZWWU5AJiZVZQDgJlZRTkAmJlVlAOAmVlFOQBYoUgaKWmspCmSRrY7PWaDWVW7grDiehvpRrPtgWGkDu3MrAWcA+hG7jN/3xat+5XhIO111O4EmFWBA0DW1Qk5InaJiFvblKSmKUqwkXS0pDm5m4hlkm6VVN+r6BzgAtL4BFcPfCrNqsMBwAaEpCmknlSnAiOBt5D6UVpeu1xELI+IhRFxaUQsf92KbFDp7uKkPgdeu2wrc+dVMugCgKSd85Xlc/lHcmjNvIWSTpX0cO607ZLc8+WPSN0U35CHMjylZvkDal5/XtIDklZKulhpOMhfKA2x+B+1lZaSpisN57gib+/D67EPjYarbLhvef4XJP0lb/MRSft3s2+vW7aPx/PkfEz+JulKScMb7NYngf+bB9GJiHgmIi7KHcjZINHM3GZ3OfDaeUXJ4XbqZU63GCJi0DxIlYaPkQZC2QB4D7AC2CnPX0jqzXJbYBTwG+DrNfMOqFvfK9Py69+SBjIZAywFfg/sAWwI/Bo4o+azHyUNhvIGUs+aK4Gtu1p33TaHkIZ1/HfgjcBwYJ9e7NtOpL77R+f3Y4EdutpWd8v24Xj+Lu/nKFIPqcc1+G5+lecfDmzR7t+KH615NPpdN2P5bv4z67XNFu//lPyfeRupLmsL4FPAiHanrcv0tjsBTT747yKNevWGmmmzgTNrfijH1cx7P/CnRj+iLgLA0TXzrgG+V/N+GnBtN2mbC3yoq3XXLbcXqV/9oeu5bzuSgtIBwLBG+9HTsn04nh+rmXcO8P0G63oz8G1Sd9Mvk8Yv3rLdvxk/+vYAvgD8hXRB8AhpDOofkcaDWAW8AJwCTAf+lJd7GPhw3XoWkoYJfZhUHHgJMLxm3gF1y9b+Hw9osM3PA9fUbec7wLcb7MvOwK3Ac8A84NC6bZ4MPAD8DbiyM30N1nUHaWjVtn9HvXkMtiKg0cCiSGPkdnqc1w5fuKhu3uj1WH/tKFarunjfOZg7kj4uaa5eHUpxIulqoCeNhmfsdt8i4jHgc8CZwFJJV0jqct/WY9neHM/6YSY3pgsR8deI+FxEbEcag/itpJOIlYyknYDPAntGxCbAQcDCiDiGFOA/GBEbR8Q5pJP/u0jjUnwFuFzS1nWrPDqvYwdS3dDpvU1Lg21eDhwsafOc3qGkXPiPutiXYaSLkV8BW5Iu5H6c97HT4cDBwDjS73ZKN0laBRwr6XBJvfm/t9VgCwBPAttKqt2v7UhXKp22rZv3ZH7dtIERlAZM/wHpT/IPEbE5qeipN80bXxmesW56j/sWEbMiYh9SG/ogDeQCXexbN8uu1zb7IiLmAA+SirisfF4mFXtOkDQsUqX9n7paMCJ+EhFPRsS6iLgSeJR0AVDrwohYFBHLSAMKTepP4iLiKdIARJ0j1x0MPJN/d/XeQbpoOTsiVkfEr0kt0GrTcEHeh2WkYLF7N5v/OGnc8HOBJZJukLRlf/anlQZbALibVNZ+iqRhuZXAB4Erapb5jKRtJI0ilW1fmaf3NKTj+ngj6aT6NICkT5ByAL3RaHjGbvdN0k6S3iNpQ9KoW6toMFxlD8vW6s3x7FGuEN9b0ob5MQXYl5Tdt5JZn9xmL3PC/cmVN3IZ8LH8+mN0cfWfNS2XC+XL6Q6qABARq4FDSXeSPgN8F/h4RPyhZrFZpOzen/Pj63n6N4HT8w/15H6m42Hg34C7SCffXUkVzr35bJfDM/Zi3zYEzs7z/krKzp7WYN+6W7Y2Lb05nr2xKelk/2zepyOA/SPi7s4FJD0k6XpJ93W2VLLi6k1ucz1ywo1y5b1OThfTrgXeKmkicAjw4wafbUkuF16f0y3kb7zdlRAD+aBArQX8eM33sjnpD7cFqbXR3HanyY9uv6+dSC3CNszf10zg0jzvt8DU/HoCKYe5E6l12yeAtcCnata1kHSS3IbUkuwO4Bs187qtBK7fZl06f0CqvP11N/uyAameYjqp1du+pArrf2qQhjOByxusazqwdz4uG5LqCl4A/ntRf+ODKgdgpbUrMDvSvQGrSTkFK65e5TZJrex6kxNulCvvrUa598vyNhsV/xDNy+VC9zndQv7GKzUovKSFpKuP/2h3WuxVkj4N7BwR0yQdBYyLiLPanS4rN0nbAX8A3hwRz7c5LYX8jVeqN9CIGNvuNFiXdgXWSLqFdEV5bJvTYyWXy/T/N3BFu0/+WSF/45UKAFZYOwIHxWtbYpj1iaQ3koqcHic1AS2CQv7GXQdgRbBB0f4Y60PSTElLJT1UM22UpJslPZqfa/uJOlXSY7kPpoPytA0l/TK3FPl0zbIzJO0xsHtUbhGxMtJNYbtExKKePzEgCvkbdwCwtouI/9HuNPTTpbz+SnM6cEtEjAduye+RNAE4Etglf+a7koaQ7oSdQ2o3PjUvuxupG477BmAfrIWK+ht3ADDrp4i4HVhWN/lDpFYo5OfDaqZfEREvRcQCUsdhbwfWABvx2mLZrwFfblGyzRwAzFpkq0hdEpCfO7sDGMNr73xdnKfdTOow727gnNzt9pyIWN+bosx6rVSVwFtssUWMHTu23cmwgpkzZ84zEfGmdqejl7rqDyoidf53FLzSQdlNwKGSziPdmfrDiLi+yxVKU8nFRiNGjHjbDjvs0JKEWzk9+OCDDf8fpQgAkj4IfHD77bfn6qs9SqC91rhx4x5vdxq6sETS1hHxVO79cmmevpjXdn2wDa/v+uDTpGKjvYDVpBuK7gK6DAARMQOYAdDR0RH33ntv03bCyk9Sw/9HKQJARNwA3NDR0fEvzgFYSVwPTCbdMTsZuK5m+qx8ZT8aGE/qABCA3FroEOBA0h2q60h93TQaac2sz1wHYNZPkmaTrtB3krRY0idJJ/73SnoUeG9+T0TMA64iDYDyS+AzkToA7PRl0ih1QSoG6iD1lfODgdofqw4HgF6aPXs2EydOZMiQIUycOJHZs2e3O0lWEBExKSK2johhEbFNRFwcEc9GxP4RMT4/L6tZ/qyI2CEidoqIX9St68SIuC2/fjEiDszt2b8z0Ptlg58DQC/Mnj2bE044gZUrVwKwcuVKTjjhBAcBMys1B4BeOOWUUxg6dCgzZ87kxRdfZObMmQwdOpRTTilGl95mZn3hANALixcvZsqUKUybNo3hw4czbdo0pkyZwuLFi9udNDOzPitFK6AiuOSSS5g1axb77LMPd955J0cddVS7k2Rm1i8OAL0wdOhQVqxYwbHHHssTTzzBdtttx4oVKxg61IfPzMrLZ7BeWLt2LevWrWPVqlWvPHe+NjMrq1IEgNo7gRcuXDjg299ggw14//vfz8MPP8zTTz/NZpttxl577cWNN97YlvSYmTVDKQJAu+8EXrNmDXPnzmXmzJmv1AEce+yxrFmzBt+ZbGZlVYoA0G4TJkzgsMMOY9q0acyfP5+dd96Zo48+mmuvvbbdSTMz6zMHgDpSV501wrx5817zuvN9o+XTnfxmZsXl+wDqRESXj1mzZrHLLrsAsMsuuzBr1qyGy/rkb2Zl4BxAL02aNIlJkyYhiYceeqjnD5iZFZxzAGZmFeUAYGZWUQ4AZmYV5QBgZlZRDgBmZhXlAGBmVlE9BgBJMyUtlfRQzbRRkm6W9Gh+Hlkz71RJj0l6RNJBedqGkn4p6SFJn65ZdoakPZq9U2Zm1rPe5AAuBQ6umzYduCUixgO35PdImgAcCeySP/NdSUOAg4A5wFuBqXnZ3YA3RMR9/d+N3hk1ahSS+vXIae/XY9SoUQO1y2ZmDfV4I1hE3C5pbN3kDwH75teXAbcCX8jTr4iIl4AFkh4D3g6sATaq297XgOP6kfb1tnz58kLcpduo+wgzs4HU1zqArSLiKYD8vGWePgZYVLPc4jztZuDNwN3AOZIOBeZExJN93L6ZmfVTs7uC6OrSNiJiLXAUgKRhwE3AoZLOA7YDfhgR13e5QmkqudhozJgx/e5/vyj99xclHWZWXX0NAEskbR0RT0naGliapy8Gtq1Zbhug/ir/06Rio72A1cARwF1AlwEgImYAMwA6Ojqiv/3vF6X//qKkw8yqq68B4HpgMnB2fr6uZvqsfGU/GhgP/K7zQ7m10CHAgcChwDoggOHdbayZI4IV5cq7KOmw1pJ0IvAp0u/8QeATwAjgSmAssBA4PCKWS9ob+B7wEjApIh6TtHle9uAoQgWWDSrq6TclaTapwncLYAlwBnAtcBWp+OYJ4KMRsSwv/0XgWGAt8LmI+EXNuv4duDYibpM0nBQwxgDfj4jv9JTYjo6OuPfee9dzF1+zL4WpBC5COgYLSXMioqPd6agnaQxwJzAhIlZJugq4EZgALIuIsyVNB0ZGxBck/ZTUmGIs6YR/kqR/A66PiNt6s83+/kds8Onu/9GbVkCTGszav8HyZwFnNZh3Ys3rF0k5gQETZ2wKZ242kJtsnA6riqHARpLWkK78nwROpetWdJ2t5UYAayTtAIzp7cnfbH2VYjyAZhUBjfvK8yxYsKBp6epzOsaNY8GUhe1OhrVYRPxF0rmkXPIq4FcR8StJr2lFJ6mzFd03SfVdq4BjgHOBL/W0nWY3lLDq6LEIqEhcBGRdKXAR0EjgGlJDh+eAnwBXAxdGxOY1yy2PiJF1n303cBjwfdI9M2uAkyJiSXfbdBGQ1evu/+G+gMxa5wBgQUQ8HRFrgJ8C7yS3ogOoa0VHnibgdNKJ/4z8uBw4fgDTbhVQqSIgKE7rm6Kkw1rqCeAdkkaQinX2B+4FVtJ1K7pOk4Gf55ZBI0it5daR6gbMmqYUASAibgBu6Ojo+Jf+tp8fN25cU9LUHyNHjvR9ABUQEXdLuhr4PalV3H2kMv6NgaskfZLciq7zM/mEP5lXG0icRypGWg00apBh1ielCADN0oxyd5ff2/qIiM4inFov0bgV3d+B/Wre3wHs2rIEWqW5DsDMrKJKkQNoZh1AMxQhDWZm/VWKANDMOoBmKEIazMz6qxQBYCD1pq/+3izjegIzKzoHgDo+cZtZVZQiABStDsDMbDAoRQAoWh2Amdlg4GagZmYV5QBgZlZRpSgCMjMbaGOn/7zdSQBg4dkfaNm6SxEAXAlsZtZ8pQgArgQ2M2s+1wGYmVWUA4CZWUU5AJiZVZQDgJlZRTkAmJlVVClaAbkZqJlZ85UiALgZqJlZ87kIyMysohwAzMwqygHAzKyiHADMzCrKAcCshSRtLulqSX+QNF/SXpJGSbpZ0qP5eWRedm9JD0i6R9KONZ+/Sb0ZiNpsPTkAmLXW+cAvI+KfgN2A+cB04JaIGA/ckt8DnAT8M3Aa8K952peAb4QHq7YWcAAwaxFJmwLvBi4GiIjVEfEc8CHgsrzYZcBh+fUaYCNgBLBG0g7AmIi4bQCTbRVSivsAfCOYldQ/Ak8Dl0jaDZgDnABsFRFPAUTEU5K2zMt/E5gBrAKOAc4l5QDMWqIUAcA3gllJDQX+GzAtIu6WdD6vFve8TkTMBd4BIOndwJPppa4k5Q5Oiogl9Z+TNBWYCjBmzBhfJDXJXluua3cSAFr6fZYiAJiV1GJgcUTcnd9fTQoASyRtna/+twaW1n4oV/ieDhwBXAicAYwFjge+WL+RiJhByjnQ0dERvkhqjruWzmt3EgBo5ffpOgCzFomIvwKLJO2UJ+0PPAxcD0zO0yYD19V9dDLw84hYTqoPWJcfI1qeaKsU5wDMWmsa8GNJGwB/Bj5BuvC6StIngSeAj3YuLGkEKQAcmCedB1wDrAYmDWC6rQIcAMxaKJfrd3Qxa/8Gy/8d2K/m/R3Ari1JnFWei4DMzCrKAcDMrKIcAMzMKsoBwMysohwAzMwqygHAzKyiHADMzCqqXwFA0kxJSyU9VDPNfZ2bmZVAf3MAlwIH101zX+dmZiXQrwAQEbcDy+omu69zM7MSaEVXEO7r3MysBAasLyD3dW5WfGOn/7zdSQBg4dkfaHcSKqEVAcB9nZuZlUArAkBnX+dn00Nf57nr2x77OveQkGZmzdevACBpNrAvsIWkxaSr+bNpcl/nHhLSzKz5+hUAIqLRSdt9nZuZFVwpBoRxEVB7jBs3rinrWbBgQVPWY2bNVYoA4CKg9ujp/jxJPS5jZsXlvoDMzCqqFDkAFwEVl78Ps/IqRQBwEVBx+fswKy8XAZmZVZQDgJlZRZWiCMh1AMXl78OsvEoRAFwHUFz+PnomaQhwL/CXiDhE0ijgSlIfWAuBw3PXKHsD3wNeAiZFxGOSNs/LHuxxM6zZXARk1nonAPNr3nvQJCsEBwCzFpK0DfAB4KKayR40yQqhFEVArgMoLn8fPfo2cAqwSc00D5pkhVCKAOA6gOLy99GYpEOApRExR9K+PS1fhEGT9tpyXZ8/20xFuLCowrEoRQCw5hs1ahTLly/v93rS+D59N3LkSJYtqx9WetDYGzhU0vuB4cCmki6nwIMm3bV0Xp8/20xFuLCowrFwHUBFLV++nIho+6MZQaioIuLUiNgmIsYCRwK/joiP8eqgSdDDoEmk+oAeB00y6wvnAMwGXtMHTTLri1IEAFcCt0ZRjmVR0tFKEXErcGt+/SweNMkKoBQBwJXArVGUY1mUdJhVjesAzMwqygHAzKyiSlEEZM0XZ2wKZ27W7mSkdJhZWzgAVJS+8nwhxvOVRJzZ7lSYVZOLgMzMKqoUOQA3A22NohzLoqTDrGpKEQDcDLQ1inIsi5IOs6pxEZCZWUU5AJiZVZQDgJlZRTkAmJlVlAOAmVlFOQCYmVWUA4CZWUWV4j4A3wjWGkU5lkVJh1nVlCIA+Eaw1hg3bly7k8DIkSN9I5hZm5QiAFjzNaMjOEmF6FDOzPrGdQBmZhXlAGBmVlEOAGZmFeUAYGZWUQ4AZmYV5QBg1iKStpX0/yXNlzRP0gl5+ihJN0t6ND+PzNP3lvSApHsk7ZinbS7pJklq577Y4OQAYNY6a4GTImJn4B3AZyRNAKYDt0TEeOCW/B7gJOCfgdOAf83TvgR8I9ze1lrAAcCsRSLiqYj4fX69ApgPjAE+BFyWF7sMOCy/XgNsBIwA1kjaARgTEbcNZLqtOnwjmNkAkDQW2AO4G9gqIp6CFCQkbZkX+yYwA1gFHAOcS8oBmLWEA4BZi0naGLgG+FxEPN+oOD8i5pKKipD0buDJ9FJXknIHJ0XEki7WPxWYCjBmzJh+9a2015br+vzZZipC/1BVOBYtCQCSZgKHAEsjYmKe9i3gfcDciPh4nnYMMCoizm9FOszaTdIw0sn/xxHx0zx5iaSt89X/1sDSus8IOB04ArgQOAMYCxwPfLF+GxExg5RzoKOjI/rTt9JdS+f1+bPNVIT+oapwLFpVB3ApcHDnG0mbAe+MiLcCQyTtKmkjYArw3Ralwayt8on8YmB+RJxXM+t6YHJ+PRm4ru6jk4GfR8RyUn3AuvwY0doUW9W0JAcQEbfnMs9O64AN8h9iI1J29vPABRGxphVpMCuAvUll+Q9KmpunnQacDVwl6ZPAE8BHOz8gaQQpAByYJ51HykGsBiYNTLKtKgakDiAiVki6BriP1Oztb8CeEfHVnj7bzPJNaz5/H41FxJ1Ao/b7+zf4zN+B/Wre3wHs2vzUmQ1gJXBEnAOcAyDpIuDLkj5FutJ5ICK+3uBzTSvftObz92FWXgN+H4CkPfLLPwIfj4jDgYmSxg90WszMqqwdzUC/RirSGQYMydO6reDykJDF5e/DrLxa1Qx0NrAvsIWkxcAZEXGxpMOAeyLiybzcXZIeJBUB3d9ofR4Ssrj8fZiVV6taAXXZWiEirgWurXl/MnByK9JgZmbdK8WdwC4CKi5/H2blVYoA4CKg4vL3YVZe7g3UzKyiSpEDcBFQcfn7MCuvUgQAFwEVl78Ps/JyEZCZWUWVIgfgIqDi8vdhVl6lCAAuAioufx9m5eUiIDOzinIAMDOrKAcAM7OKKkUdgCuBi8vfh1l5lSIAuBK4uPx9mJWXi4DMzCrKAcDMrKJKUQRk7SE1Gs98/ZaJiGYkx8yarBQBwJXA7bFgwYKmrMffmVkxlSIAuBLYzKz5XAdgZlZRDgBmbSDpYEmPSHpM0vQ87VuSHpD0w5rljpF0QvtSaoOZA4DZAJM0BPg/wPuACcAkSbsB74yItwJDJO0qaSNgCvDdtiXWBrVS1AGYDTJvBx6LiD8DSLoCOBTYQKlZ1UbAGuDzwAURsaZtKbVBzTkAs4E3BlhU834xsBVwDXAfsAD4G7BnRFw38MmzqihFDqCzGSjwvKRH25ycLYBn2pyGoijKsdi+3QlYT13dPBERcQ5wDoCki4AvS/oUcCDwQER8vcuVSVOBqfntC5IeaUGa10e/fxf6VpNS0n5FOBYN/x+lCACdzUB59UfeNpLujYiOdqejCHws+mwxsG3N+22AJzvfSNojv/wjcH5EvFvSFZLGR8TrLoAiYgYwo5UJXh/+Xbyq6MfCRUBmA+8eYLykcZI2AI4Erq+Z/zXgy8AwYEietg4YMaCptEHPAcBsgEXEWuCzwE3AfOCqiJgHIOkw4J6IeDIingPukvRg+ljc36Yk2yAl99OyfiRNzVnuyvOxsK74d/Gqoh8LBwAzs4pyEZCZWUVVLgBIelnSXEkPSbpB0uZ5+mhJVzdxO2MlHVXzvkPSBc1af7vUHb+fSBqRp7/Q7rRZc/g/0j9l+o9ULgAAqyJi94iYCCwDPgOQK90+0sTtjAVe+XFHxL0RcXwT198utcdvNXBcuxNkTef/SP+U5j9SxQBQ6y7SXZmdVyMP5ddDJJ0r6cHcOde0PH1PSf8p6X5Jv5O0Sf7cHZJ+nx/vzOs+G3hXvhI4UdK+kn7Wlr1snTuAHdudCGsp/0f6p9D/kVLcCNYKuUOu/YGLu5g9FRgH7BERayWNyu21rwSOiIh7JG0KrAKWAu+NiBcljQdmAx3AdODkiDgkb2/fVu/TQJI0lNSZ2S/bnRZrDf9H+qcM/5EqBoCNJM0lZT/nADd3scwBwPdze20iYpmkXYGnIuKePO15AElvBC6UtDvwMvCWVu9Am3UeP0hXN12dHKzc/B/pn9L8R6oYAFZFxO6SNgN+RirfrK94ElDfPraraQAnAkuA3UhFai82N7mFsyoidm93Iqyl/B/pn9L8RypbBxARfwOOB06WNKxu9q+A43IWDkmjgD8AoyXtmadtkudvRrrqWQccw6u37q8ANmn9npi1hv8jg19lAwBARNwH3E/qi6XWRcATwAOS7geOiojVwBHAd/K0m4HhpME6Jkv6LSlruzKv4wFgba4MO7H1e2PWfP6PDG6+E9jMrKIqnQMwM6syBwAzs4pyADAzqygHADOzinIAMDOrKAcAM7OKcgAwM6soBwAzs4r6Lyug1OOuyeIcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test sample set Sp with 2000 polynomial states\n",
    "test_filename = 'Sp.samples'\n",
    "dataset = pickle.load(open(test_filename,'rb'))\n",
    "\n",
    "# calculate costs for Sp controlled with pi feedback model\n",
    "env.set_feedback(controller)\n",
    "_, COSTS_pi = case.transport_states(dataset['X0'], dt=dt, k=int(5/dt))\n",
    "\n",
    "# difference to optimal costs for k first (most expensive) states\n",
    "k = 100\n",
    "D_pi = (COSTS_pi[:k].flatten() - dataset['costs'][:k])/dataset['costs'][:k]*100\n",
    "D_ricc = (dataset['costs_riccati'][:k] - dataset['costs'][:k])/dataset['costs'][:k]*100\n",
    "\n",
    "# stability\n",
    "S_pi = (len(COSTS_pi) - np.sum(np.isnan(COSTS_pi)))/len(COSTS_pi)*100\n",
    "S_ricc = (len(dataset['costs_riccati']) - np.sum(np.isnan(dataset['costs_riccati'])))/len(dataset['costs_riccati'])*100\n",
    "\n",
    "#plot\n",
    "fig, axes = plt.subplots(1,2, figsize=(6,3))\n",
    "axes[0].set_title('cost diffrence to\\n' + r'optimal costs on $S_p^*$')\n",
    "axes[0].boxplot([D_ricc, D_pi], widths=0.5)\n",
    "axes[0].set_yscale('log')\n",
    "axes[0].set_xticklabels(['Riccati','PI'])\n",
    "axes[0].set_xlim([0.5, 2.5])\n",
    "axes[0].grid(axis='y', which='both', alpha=0.5)\n",
    "axes[0].set_yticklabels([str(int(x)) + '%' for x in axes[0].get_yticks()])\n",
    "axes[1].set_title(r'stability on $S_p$')\n",
    "axes[1].bar([1,2], [S_ricc, S_pi], width=0.5)\n",
    "axes[1].set_xticks([1,2])\n",
    "axes[1].set_xticklabels(['Riccati','PI'])\n",
    "axes[1].set_ylim([0,100])\n",
    "axes[1].grid(axis='y', alpha=0.5)\n",
    "axes[1].set_xlim([0.5, 2.5])\n",
    "axes[1].set_yticklabels([str(int(x)) + '%' for x in axes[1].get_yticks()])\n",
    "plt.subplots_adjust(wspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a66fed2",
   "metadata": {},
   "source": [
    "# ANALYSIS ON SINGLE STATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f114af0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feedback set: <function InfiniteHorizon.feedback_from_value.<locals>.feedback at 0x0000027165918D30>\n",
      "integrating system dynamics with assigned feedback control, done on ...\r"
     ]
    }
   ],
   "source": [
    "# 1\n",
    "# test on single state\n",
    "x = dataset['X0'][0]\n",
    "\n",
    "# set model feedback obtained from policy iteration and calculate trajectory\n",
    "env.set_feedback(controller)\n",
    "TRJ_pi = env.integrate_closedloop(x[None,...], dt, int(5/dt))\n",
    "u_pi = TRJ_pi[2]\n",
    "costs_pi = case.value_trajectory(TRJ_pi)\n",
    "\n",
    "# riccati control and costs for comparison\n",
    "env.set_feedback_linear(case.K)\n",
    "TRJ_ricc = env.integrate_closedloop(x[None,...], dt, int(5/dt))\n",
    "u_ricc = TRJ_ricc[2]\n",
    "costs_ricc = case.value_trajectory(TRJ_ricc)\n",
    "\n",
    "# plot\n",
    "fig, axes = plt.subplots(1,2, figsize=(8,3))\n",
    "axes[0].set_title('considered state')\n",
    "axes[0].plot(xi, x, 'k:o')\n",
    "axes[0].set_xlabel(r'$\\xi$')\n",
    "axes[1].set_title('control signals')\n",
    "axes[1].plot(TRJ_ricc[0], u_ricc, label='Riccati, costs: {:.3f}'.format(costs_ricc[1]))\n",
    "axes[1].plot(TRJ_pi[0], u_pi, label='PI model, costs: {:.3f}'.format(costs_pi[1]))\n",
    "axes[1].set_xlabel('t')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16244339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n",
    "# test on single state\n",
    "xi = np.linspace(-1,1,len(limits))\n",
    "x = (xi-1)*(xi+1)/1000*(-2749*xi**4 - 905*xi**3 - 2463*xi**2 - 3570*xi + 712)\n",
    "\n",
    "# set model feedback obtained from policy iteration and calculate trajectory\n",
    "env.set_feedback(controller)\n",
    "TRJ_pi = env.integrate_closedloop(x[None,...], dt, int(5/dt))\n",
    "u_pi = TRJ_pi[2]\n",
    "costs_pi = case.value_trajectory(TRJ_pi)\n",
    "\n",
    "# riccati control and costs for comparison\n",
    "env.set_feedback_linear(case.K)\n",
    "TRJ_ricc = env.integrate_closedloop(x[None,...], dt, int(5/dt))\n",
    "u_ricc = TRJ_ricc[2]\n",
    "costs_ricc = case.value_trajectory(TRJ_ricc)\n",
    "\n",
    "# plot\n",
    "fig, axes = plt.subplots(1,2, figsize=(8,3))\n",
    "axes[0].set_title('considered state')\n",
    "axes[0].plot(xi, x, 'k:o')\n",
    "axes[0].set_xlabel(r'$\\xi$')\n",
    "axes[1].set_title('control signals')\n",
    "axes[1].plot(TRJ_ricc[0], u_ricc, label='Riccati, costs: {:.3f}'.format(costs_ricc[1]))\n",
    "axes[1].plot(TRJ_pi[0], u_pi, label='PI model, costs: {:.3f}'.format(costs_pi[1]))\n",
    "axes[1].set_xlabel('t')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
